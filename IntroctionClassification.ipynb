{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce TP est de programmer et de tester 2 algorithmes de classification très simples mais très efficaces. L'algorithme du Plus Proche Voisin (PPV) et le classifieur Baysien Naïf (CBN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliothèques utiles\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier #algo des K plus proche voisins de sklearn\n",
    "from sklearn import metrics #permet de calculer les distances entre données\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Plus proche voisin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme du Plus Proche Voisin est un algorithme très simple de classification qui repose sur le principe suivant : **La classe de chaque donnée de test (à classer) doit être la classe de la donnée la plus proche (le plus similaire) parmi les données d'apprentissage**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Création d'une fonction PPV(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction prend en entrée les données X et les étiquettes Y puis renvoie une étiquette pour chaque donnée prédite à partir du plus proche voisin de cette donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPV(data, target):\n",
    "    Y_pred=[]\n",
    "    #calcule la distance euclidienne entre les données pour trouver celui qui est le plus proche d'une donnée quelconque\n",
    "    distance = metrics.pairwise.euclidean_distances(data) \n",
    "    #Parcours de toutes les distances\n",
    "    for i, point in enumerate(distance): #i = clé ; point = valeur ; enumerate(distance) = un dictionnaire\n",
    "        # On supprime la valeur en position i de la matrice point courante par delete(point,i)\n",
    "        #puis on les stocke dans une matrice contenant les voisins de l'elt à la position i de point\n",
    "        #la matrice point passe de 150 observations à 149\n",
    "        voisins = np.delete(point,i)\n",
    "        # par la suite on récupère l'indice du minimum de la nouvelle matrice par argmin\n",
    "        #Le plus petit voisin de l'elt à la position i de la matrice point\n",
    "        # il correspond à la distance minimale et donc à l'indice de l'elt le plus proche de i de point\n",
    "        min_voisin = np.argmin(voisins)\n",
    "        #on récupère l'étiquette du plus proche voisin de l'elt à la position i       \n",
    "        Y_pred.append(target[min_voisin])\n",
    "    return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Erreur de prédiction : Pourcentage d'étiquettes mal prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPV_erreur(data, target):\n",
    "    Y_pred=[]\n",
    "    erreur = []\n",
    "    distance = metrics.pairwise.euclidean_distances(data) \n",
    "    #Parcours de toutes les distances\n",
    "    for i, point in enumerate(distance): \n",
    "        voisins = np.delete(point,i)\n",
    "        min_voisin = np.argmin(voisins)\n",
    "        Y_pred.append(target[min_voisin])\n",
    "        #Y_pred = np.array(Y_pred)\n",
    "    \n",
    "    #calcul de l'erreur\n",
    "    erreur.append(np.mean(Y_pred != Y))\n",
    "\n",
    "    return (erreur[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test sur les données Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquettes des données prédites :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Erreur de prédiction :  4.0 %\n"
     ]
    }
   ],
   "source": [
    "# Données iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data #les données\n",
    "Y = iris.target # les étiquettes\n",
    "\n",
    "# étiquettes des données prédites\n",
    "Y_pred = PPV(X,Y)\n",
    "print(\"Etiquettes des données prédites : \", Y_pred)\n",
    "\n",
    "# Erreur de prédiction\n",
    "erreur = PPV_erreur(X,Y)\n",
    "print(\"Erreur de prédiction : \",erreur,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test de la fonction des k plus proches voisins de sklearn (avec k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prédiction pour k=1 :  0.0 %\n"
     ]
    }
   ],
   "source": [
    "# Test avec k=1\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, Y) \n",
    "#prédiction des étiquettes\n",
    "pred = knn.predict(X)\n",
    "error = []\n",
    "error.append(np.mean(pred != Y))\n",
    "print(\"Erreur de prédiction pour k=1 : \", error[0]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prédiction pour k =  1  :  0.0 %\n",
      "Erreur de prédiction pour k =  2  :  2.0 %\n",
      "Erreur de prédiction pour k =  3  :  4.0 %\n",
      "Erreur de prédiction pour k =  4  :  4.0 %\n",
      "Erreur de prédiction pour k =  5  :  3.33 %\n",
      "Erreur de prédiction pour k =  6  :  2.67 %\n",
      "Erreur de prédiction pour k =  7  :  2.67 %\n",
      "Erreur de prédiction pour k =  8  :  2.0 %\n",
      "Erreur de prédiction pour k =  9  :  2.0 %\n",
      "Erreur de prédiction pour k =  10  :  2.0 %\n"
     ]
    }
   ],
   "source": [
    "# Test avec d'autres valeurs\n",
    "# On considère les k de 1 à 10\n",
    "for k in range(1,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X, Y) \n",
    "    #prédiction des étiquettes\n",
    "    pred = knn.predict(X)\n",
    "    error = []\n",
    "    error.append(np.mean(pred != Y))\n",
    "    print(\"Erreur de prédiction pour k = \",k,\" : \",round(error[0]*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont différents de ceux obtenus avec notre algorithme car il n'y a pas d'erreur de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Classifieur Bayesien Naïf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme du classifieur Bayésien Naïf est un algorithme de classification basé sur le calcul de probabilité d'appartenance à chaque classe. C'est à dire que la donnée de test (à classer) sera affectée à la classe la plus probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fonction CBN(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBN(X, Y):\n",
    "    # liste des moyennes (barycentre) de la classe\n",
    "    moy = [np.mean(X[(Y==0)], axis=0), np.mean(X[(Y==1)], axis=0), np.mean(X[(Y==2)], axis=0)]\n",
    "    # on convertit cette liste de moyenne en tableau numpy plus facile à manipuler\n",
    "    moy=np.asarray(moy)\n",
    "\n",
    "    # distance euclidienne entre une donnée X et le barycentre (moyenne) de la classe\n",
    "    dxk = metrics.pairwise.euclidean_distances (X, moy)\n",
    "    \n",
    "    # somme des distances entre la donnée X et chaque barycentre de chaque classe\n",
    "    dxb=np.sum(dxk, axis=1)\n",
    "    \n",
    "    pxk = np.zeros(450,dtype=float).reshape((150, 3))\n",
    "    for i in range (0,len(dxb)):\n",
    "        for j in range (0, 3):\n",
    "            # probabilité qu'une donnée X ait la valeur Xi pour la variable i connaissant sa classe\n",
    "            pxk[i][j]=1-(dxk[i][j]/dxb[i]) \n",
    "    \n",
    "    # propabilité d'appartenance à chaque classe\n",
    "    Ybay=np.argmax(pxk, axis=1)\n",
    "    return Ybay    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Erreur de prédiction (pourcentage d'étiquettes mal prédites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBN_erreur(X, Y):\n",
    "    #Y_pred=[]\n",
    "    erreur = []\n",
    "    # liste des moyennes (barycentre) de la classe\n",
    "    moy = [np.mean(X[(Y==0)], axis=0), np.mean(X[(Y==1)], axis=0), np.mean(X[(Y==2)], axis=0)]\n",
    "    # on convertit cette liste de moyenne en tableau numpy plus facile à manipuler\n",
    "    moy=np.asarray(moy)\n",
    "\n",
    "    # distance euclidienne entre une donnée X et le barycentre (moyenne) de la classe\n",
    "    dxk = metrics.pairwise.euclidean_distances (X, moy)\n",
    "    \n",
    "    # somme des distances entre la donnée X et chaque barycentre de chaque classe\n",
    "    dxb=np.sum(dxk, axis=1)\n",
    "    \n",
    "    # On crée une matrice qui doit contenir les probabilités de chaque puis on le redimensionne\n",
    "    # en 2 D. Sachant qu'ici on a 3 classe unique et comme pour chaque classe\n",
    "    # il y aura 150 éléments, on aura donc en tout 450 éléments dans cette matrice\n",
    "    pxk = np.zeros(450,dtype=float).reshape((150, 3))\n",
    "    for i in range (0,len(dxb)):\n",
    "        for j in range (0, 3):\n",
    "            # probabilité qu'une donnée X ait la valeur Xi pour la variable i connaissant sa classe\n",
    "            pxk[i][j]=1-(dxk[i][j]/dxb[i]) \n",
    "    \n",
    "    # propabilité d'appartenance à chaque classe\n",
    "    Y_pred=np.argmax(pxk, axis=1)\n",
    "    \n",
    "    # calcul de l'erreur\n",
    "    erreur.append(np.mean(Y_pred != Y))\n",
    "    \n",
    "    return round((erreur[0]*100), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Test sur les données iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage d'étiquettes mal prédites est de  7.33 %\n"
     ]
    }
   ],
   "source": [
    "erreur = CBN_erreur(X, Y)\n",
    "print(\"Le pourcentage d'étiquettes mal prédites est de \",erreur,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test de la fonction du classifieur Bayesien Naïf inclu dans sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Erreur de prédiction :  4.0 %\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X, Y)\n",
    "y_pred = gnb.predict(X)\n",
    "print(y_pred)\n",
    "e = []\n",
    "e.append(np.mean(y_pred != Y))\n",
    "print(\"Erreur de prédiction : \", e[0]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats ont bel et bien différents car avec notre fonction on a eu une erreur de prédiction de 7 % mais avec la fonction du classifieur bayesien naif inclu dans sklearn, l'erreur est de 4%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
